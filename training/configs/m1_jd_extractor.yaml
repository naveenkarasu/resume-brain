model:
  name: m1_jd_extractor
  base: bert-base-cased
  num_labels: 19  # 9 entity types x 2 (B/I) + O
  task: token_classification

data:
  sources:
    - skillspan
    - green
    - jd2skills
    - google_job_skills
    - djinni
    - sayfullina
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  max_length: 512

training:
  epochs: 10
  batch_size: 16
  learning_rate: 3.0e-5
  weight_decay: 0.01
  warmup_ratio: 0.1
  optimizer: adamw
  scheduler: linear
  early_stopping_patience: 3
  early_stopping_metric: eval_f1
  fp16: true

evaluation:
  metric: entity_level_macro_f1
  target: 0.85

output:
  model_dir: training/models/m1_jd_extractor
  log_dir: training/logs/m1_jd_extractor
